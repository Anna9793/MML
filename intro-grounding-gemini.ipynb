{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2025 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Intro to Grounding with Gemini in Vertex AI\n",
    "\n",
    "<table align=\"left\">\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.gstatic.com/pantheon/images/bigquery/welcome_page/colab-logo.svg\" alt=\"Google Colaboratory logo\"><br> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2FGoogleCloudPlatform%2Fgenerative-ai%2Fmain%2Fgemini%2Fgrounding%2Fintro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" alt=\"Google Cloud Colab Enterprise logo\"><br> Run in Colab Enterprise\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img width=\"32px\" src=\"https://www.svgrepo.com/download/217753/github.svg\" alt=\"GitHub logo\"><br> View on GitHub \n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/main/gemini/grounding/intro-grounding-gemini.ipynb\">\n",
    "      <img src=\"https://www.gstatic.com/images/branding/gcpiconscolors/vertexai/v1/32px.svg\" alt=\"Vertex AI logo\"><br> Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "  <td style=\"text-align: center\">\n",
    "    <a href=\"https://goo.gle/4jeQyFS\">\n",
    "      <img width=\"32px\" src=\"https://cdn.qwiklabs.com/assets/gcp_cloud-e3a77215f0b8bfa9b3f611c0d2208c7e8708ed31.svg\" alt=\"Google Cloud logo\"><br> Open in  Cloud Skills Boost\n",
    "    </a>\n",
    "  </td>\n",
    "</table>\n",
    "\n",
    "<div style=\"clear: both;\"></div>\n",
    "\n",
    "<b>Share to:</b>\n",
    "\n",
    "<a href=\"https://www.linkedin.com/sharing/share-offsite/?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/8/81/LinkedIn_icon.svg\" alt=\"LinkedIn logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://bsky.app/intent/compose?text=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/7/7a/Bluesky_Logo.svg\" alt=\"Bluesky logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://twitter.com/intent/tweet?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/5a/X_icon_2.svg\" alt=\"X logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://reddit.com/submit?url=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://redditinc.com/hubfs/Reddit%20Inc/Brand/Reddit_Logo.png\" alt=\"Reddit logo\">\n",
    "</a>\n",
    "\n",
    "<a href=\"https://www.facebook.com/sharer/sharer.php?u=https%3A//github.com/GoogleCloudPlatform/generative-ai/blob/main/gemini/grounding/intro-grounding-gemini.ipynb\" target=\"_blank\">\n",
    "  <img width=\"20px\" src=\"https://upload.wikimedia.org/wikipedia/commons/5/51/Facebook_f_logo_%282019%29.svg\" alt=\"Facebook logo\">\n",
    "</a>            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49e1e41cea0d"
   },
   "source": [
    "| Authors |\n",
    "| --- |\n",
    "| [Holt Skinner](https://github.com/holtskinner) |\n",
    "| [Kristopher Overholt](https://github.com/koverholt) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "**YouTube Video: Introduction to grounding with Gemini on Vertex AI**\n",
    "\n",
    "<a href=\"https://www.youtube.com/watch?v=Ph0g6dnsB4g&list=PLIivdWyY5sqJio2yeg1dlfILOUO2FoFRx\" target=\"_blank\">\n",
    "  <img src=\"https://img.youtube.com/vi/Ph0g6dnsB4g/maxresdefault.jpg\" alt=\"Introduction to grounding with Gemini on Vertex AI\" width=\"500\">\n",
    "</a>\n",
    "\n",
    "[Grounding in Vertex AI](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/ground-gemini) lets you use generative text models to generate content grounded in your own documents and data. This capability lets the model access information at runtime that goes beyond its training data. By grounding model responses in Google Search results or data stores within [Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/enterprise-search-introduction), LLMs that are grounded in data can produce more accurate, up-to-date, and relevant responses.\n",
    "\n",
    "Grounding provides the following benefits:\n",
    "\n",
    "- Reduces model hallucinations (instances where the model generates content that isn't factual)\n",
    "- Anchors model responses to specific information, documents, and data sources\n",
    "- Enhances the trustworthiness, accuracy, and applicability of the generated content\n",
    "\n",
    "You can configure two different sources of grounding in Vertex AI:\n",
    "\n",
    "1. Google Search results for data that is publicly available and indexed.\n",
    "   - If you use this service in a production application, you will also need to [use a Google Search entry point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points).\n",
    "2. [Data stores in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest), which can include your own data in the form of website data, unstructured data, or structured data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "In this tutorial, you learn how to:\n",
    "\n",
    "- Generate LLM text and chat model responses grounded in Google Search results\n",
    "- Compare the results of ungrounded LLM responses with grounded LLM responses\n",
    "- Create and use a data store in Vertex AI Search to ground responses in custom documents and data\n",
    "- Generate LLM text and chat model responses grounded in Vertex AI Search results\n",
    "\n",
    "This tutorial uses the following Google Cloud AI services and resources:\n",
    "\n",
    "- Vertex AI\n",
    "- Vertex AI Search\n",
    "\n",
    "The steps performed include:\n",
    "\n",
    "- Configuring the LLM and prompt for various examples\n",
    "- Sending example prompts to generative text and chat models in Vertex AI\n",
    "- Setting up a data store in Vertex AI Search with your own data\n",
    "- Sending example prompts with various levels of grounding (no grounding, web grounding, data store grounding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BF1j6f9HApxa"
   },
   "source": [
    "## Before you begin\n",
    "\n",
    "### Set up your Google Cloud project\n",
    "\n",
    "**The following steps are required, regardless of your notebook environment.**\n",
    "\n",
    "1. [Select or create a Google Cloud project](https://console.cloud.google.com/cloud-resource-manager). When you first create an account, you get a $300 free credit towards your compute/storage costs.\n",
    "1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
    "1. Enable the [Vertex AI and Vertex AI Search APIs](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,discoveryengine.googleapis.com).\n",
    "1. If you are running this notebook locally, you need to install the [Cloud SDK](https://cloud.google.com/sdk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7EUnXsZhAGF"
   },
   "source": [
    "### Install Google Gen AI SDK for Python\n",
    "\n",
    "Install the following packages required to execute this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2b4ef9b72d43",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~uth'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~auth2'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet google-genai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WReHDGG5g0XY"
   },
   "source": [
    "### Set Google Cloud project information and create client\n",
    "\n",
    "To get started using Vertex AI, you must have an existing Google Cloud project and [enable the Vertex AI API](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com).\n",
    "\n",
    "Learn more about [setting up a project and a development environment](https://cloud.google.com/vertex-ai/docs/start/cloud-environment).\n",
    "\n",
    "**If you don't know your project ID**, try the following:\n",
    "* Run `gcloud config list`.\n",
    "* Run `gcloud projects list`.\n",
    "* See the support page: [Locate the project ID](https://support.google.com/googleapi/answer/7014113)\n",
    "\n",
    "You can also change the `LOCATION` variable used by Vertex AI. Learn more about [Vertex AI regions](https://cloud.google.com/vertex-ai/docs/general/locations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oM1iC_MfAts1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-04-8cf57c9e65ec\"\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"global\")\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Markdown\n",
    "from IPython.display import display\n",
    "from google.genai.types import (\n",
    "    EnterpriseWebSearch,\n",
    "    GenerateContentConfig,\n",
    "    GenerateContentResponse,\n",
    "    GoogleMaps,\n",
    "    GoogleSearch,\n",
    "    LatLng,\n",
    "    Part,\n",
    "    Retrieval,\n",
    "    RetrievalConfig,\n",
    "    Tool,\n",
    "    ToolConfig,\n",
    "    VertexAISearch,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e569c5d4a49"
   },
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "307f36dbd36c"
   },
   "outputs": [],
   "source": [
    "def print_grounding_data(response: GenerateContentResponse) -> None:\n",
    "    \"\"\"Prints Gemini response with grounding citations in Markdown format.\"\"\"\n",
    "    if not (response.candidates and response.candidates[0].grounding_metadata):\n",
    "        print(\"Response does not contain grounding metadata.\")\n",
    "        display(Markdown(response.text))\n",
    "        return\n",
    "\n",
    "    grounding_metadata = response.candidates[0].grounding_metadata\n",
    "    markdown_parts = []\n",
    "\n",
    "    # Citation indexes are in bytes\n",
    "    ENCODING = \"utf-8\"\n",
    "    text_bytes = response.text.encode(ENCODING)\n",
    "    last_byte_index = 0\n",
    "\n",
    "    if grounding_metadata.grounding_supports:\n",
    "        for support in grounding_metadata.grounding_supports:\n",
    "            markdown_parts.append(\n",
    "                text_bytes[last_byte_index : support.segment.end_index].decode(ENCODING)\n",
    "            )\n",
    "\n",
    "            # Generate and append citation footnotes (e.g., \"[1][2]\")\n",
    "            footnotes = \"\".join([f\"[{i + 1}]\" for i in support.grounding_chunk_indices])\n",
    "            markdown_parts.append(f\" {footnotes}\")\n",
    "\n",
    "            # Update index for the next segment\n",
    "            last_byte_index = support.segment.end_index\n",
    "\n",
    "    # Append any remaining text after the last citation\n",
    "    if last_byte_index < len(text_bytes):\n",
    "        markdown_parts.append(text_bytes[last_byte_index:].decode(ENCODING))\n",
    "\n",
    "    markdown_parts.append(\"\\n\\n----\\n## Grounding Sources\\n\")\n",
    "\n",
    "    if grounding_metadata.grounding_chunks:\n",
    "        # Build Grounding Sources Section\n",
    "        markdown_parts.append(\"### Grounding Chunks\\n\")\n",
    "        for i, chunk in enumerate(grounding_metadata.grounding_chunks, start=1):\n",
    "            context = chunk.web or chunk.retrieved_context or chunk.maps\n",
    "            if not context:\n",
    "                continue\n",
    "\n",
    "            uri = context.uri\n",
    "            title = context.title or \"Source\"\n",
    "\n",
    "            # Convert GCS URIs to public HTTPS URLs\n",
    "            if uri and uri.startswith(\"gs://\"):\n",
    "                uri = uri.replace(\n",
    "                    \"gs://\", \"https://storage.googleapis.com/\", 1\n",
    "                ).replace(\" \", \"%20\")\n",
    "\n",
    "            markdown_parts.append(f\"{i}. [{title}]({uri})\\n\")\n",
    "            if hasattr(context, \"place_id\") and context.place_id:\n",
    "                markdown_parts.append(f\"    - Place ID: `{context.place_id}`\\n\\n\")\n",
    "            if hasattr(context, \"text\") and context.text:\n",
    "                markdown_parts.append(f\"{context.text}\\n\\n\")\n",
    "\n",
    "    # Add Search/Retrieval Queries\n",
    "    if grounding_metadata.web_search_queries:\n",
    "        markdown_parts.append(\n",
    "            f\"\\n**Web Search Queries:** {grounding_metadata.web_search_queries}\\n\"\n",
    "        )\n",
    "        if grounding_metadata.search_entry_point:\n",
    "            markdown_parts.append(\n",
    "                f\"\\n**Search Entry Point:**\\n{grounding_metadata.search_entry_point.rendered_content}\\n\"\n",
    "            )\n",
    "    elif grounding_metadata.retrieval_queries:\n",
    "        markdown_parts.append(\n",
    "            f\"\\n**Retrieval Queries:** {grounding_metadata.retrieval_queries}\\n\"\n",
    "        )\n",
    "\n",
    "    display(Markdown(\"\".join(markdown_parts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55cf2dd17690"
   },
   "source": [
    "Initialize the Gemini model from Vertex AI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "652a8969dd5a"
   },
   "outputs": [],
   "source": [
    "MODEL_ID = \"gemini-2.5-flash\"  # @param {type: \"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e336da7161af"
   },
   "source": [
    "## Example: Grounding with Google Search results\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search. You'll ask a question about a the most recent solar eclipse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "6a28ca4abb52"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What is today's date?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25955ce5d263"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "a2e348ff93e6"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Today is **Wednesday, May 15, 2024**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5d7cb7cceb99"
   },
   "source": [
    "### Text generation grounded in Google Search results\n",
    "\n",
    "You can add the `tools` keyword argument with a `Tool` including `GoogleSearch` to instruct Gemini to first perform a Google Search with the prompt, then construct an answer based on the web search results.\n",
    "\n",
    "The search queries and [Search Entry Point](https://cloud.google.com/vertex-ai/generative-ai/docs/multimodal/grounding-search-entry-points) are available for each `Candidate` in the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1d9fb83b0ab9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Today's date is Thursday, December 18, 2025.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"What is today's date?\"\n",
    "\n",
    "google_search_tool = Tool(google_search=GoogleSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[google_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6d3920bb2ac0"
   },
   "source": [
    "Note that the response without grounding only has limited information from the LLM about solar eclipses. Whereas the response that was grounded in web search results contains the most up to date information from web search results that are returned as part of the LLM with grounding request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59c98ab0f5fb"
   },
   "source": [
    "### Text generation with multimodal input grounded in Google Search results\n",
    "\n",
    "Gemini can also generate grounded responses with multimodal input. Let's try with this image of the Eiffel Tower.\n",
    "\n",
    "![Paris](https://storage.googleapis.com/github-repo/generative-ai/gemini/grounding/paris.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5ebdda19afad"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current temperature in Paris, France, is 14 °C (57 °F), and it feels like 13 °C (55 °F). [1] The weather is currently cloudy. [1]\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [Weather information for Paris, FR](https://www.google.com/search?q=weather+in+Paris,+FR)\n",
       "\n",
       "**Web Search Queries:** ['current temperature in Paris, France']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQG4-jDg7FmdMEmkoEGT018Vxi_Yp9c1oT2VNbl-6hALC4286dwC8jtKTjd0U9eg6_8nMHaYHsh9Py0L14tyV0G7GxZX0YahLGrO-r84AR6WRZpJhtODhuEY4e7fE6XMzpWVfvf6f-DC6n9GYPBbmsBaxAV0bDmX2EvjpSqoCehHp4uZReO4Rhq3DTf6zURJE9Gv8qSLjVpNeEmfs-LipOoFw7ycqetvug==\">current temperature in Paris, France</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"What is the current temperature at this location?\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        Part.from_uri(\n",
    "            file_uri=\"gs://github-repo/generative-ai/gemini/grounding/paris.jpg\",\n",
    "            mime_type=\"image/jpeg\",\n",
    "        ),\n",
    "        PROMPT,\n",
    "    ],\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[google_search_tool],\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a29c93ef3f34"
   },
   "source": [
    "## Example: Grounding with Enterprise Web Search\n",
    "\n",
    "Grounding with Google Search uses Google Search to perform searches across the web. As part of this offering, Google Search might perform logging of customer queries (see [section 19.k of Google Cloud Service Specific Terms](https://cloud.google.com/terms/service-terms)). This often doesn't meet the compliance requirements of customers in highly regulated industries like Finance or Healthcare.\n",
    "\n",
    "Enterprise Web Search meets these requirements. When a customer uses Enterprise Web Search to ground on the web, this is done without logging of customer data and with full support for VPC SC and ML processing in-region. Enterprise Web Search Grounding is available in an US and EU multi-region.\n",
    "\n",
    "Request and response format for Enterprise Web Search Grounding are very similar to Grounding with Google Search.\n",
    "\n",
    "### Gemini model compatibility\n",
    "\n",
    "Enterprise Web Search is compatible with all Gemini 2.5 Flash models which support grounding. Gemini 2.5 Flash supports multimodal input (e.g. images, documents, videos). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "b2587492ab3f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "There was no UEFA European Championship for senior men's national teams held in 2025. The UEFA European Championship (Euro) is typically held every four years, with the last tournament before 2025 having taken place in 2024, and the next scheduled for 2028.\n",
       "\n",
       "However, several other UEFA competitions concluded in 2025:\n",
       "*   **2025 UEFA European Under-21 Championship**: England won this tournament, defeating Germany in the final. [1]\n",
       "*   **2025 UEFA Women's Euro**: England secured the title, beating Spain in the final. [2][3]\n",
       "*   **2025 UEFA Champions League** (a club competition): Paris Saint-Germain emerged as champions after defeating Inter Milan in the final. [4]\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHXoimBAWa5daRF6ZzUF06emgi-pJxh44OZUdQTK0_gPkddMsRxO8oUbCiBUJ4QL0KcdzxamwqxJYYhabLYcK8ldNnU0yG3sHlJcthbFxnENUysxxe1HTUeeXHR1HWRQowb4Vh8epfAEsgX8OjNzdHTzxOqCExIcU1NfiHUSIYAwzs=)\n",
       "2. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQE8wkvsZ3py99-r5gFd1zXuxiVTFegCXI_uNLp6Sn1kIWAvabQUxJZggcgzW2hHsmx9iOEE2rpDdKgKTvNkRRO42Gqhq5A87VcQdnR-6OLYrlfGTsY97Xh24eeHFg_aAN6D7wWnYbeVyF4l4szhaPh01ijmrQ==)\n",
       "3. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGWvHlYnkDCrrhYcRosuSbOOQM4mPbXslJQiyGm3qskgmcLJ9dzhjTSlNkpCT_28X0gUeQYd8FzBLj71XC7uze6769gjHlO-zsR8v51MRNpfULWdADGrFnLiZFPV2__p2kuLIlP6lbnvrlvfucvf0eeUQ==)\n",
       "4. [wikipedia.org](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEbYgnnrWpTdz3YlL-SbkLACZNY8nmvxj6sYH0PcbVrdP649LCcuCHD78ZBXh1LJrk6UUFshV-C8fCpW3Mk3tPl5BUOUX8TEhI6ZbgNCiV2oQ0d2zULHeJKODZIYD1DEJqNIVdPexW5ZQgR4AYY2bc-brrIZO0YknCk)\n",
       "\n",
       "**Web Search Queries:** ['who won 2025 UEFA European Championship']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGfOqNSGIz5hh21Juifz4oQpwb5zBT33Qq8pdY1wBQDD1ypHJVQuGn_4xUkriIPywIbo_dyptR7nLihNZX6lZ43CV1GZaxLWHyTvh6vb59YZbWqvYkbjnnuE50w5aWcdvSTlWB0CZ5TU3XojkMhSpjTEY1LqUBHwlBneFZf05mBysJaIBsYH6Tq7TPy6rlyAu6YlGeMGDCkCaf_Tve8fWaTNIYw9sb1WdYqRQ==\">who won 2025 UEFA European Championship</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PROMPT = \"Who won the 2025 UEFA European Championship?\"\n",
    "\n",
    "enterprise_web_search_tool = Tool(enterprise_web_search=EnterpriseWebSearch())\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(tools=[enterprise_web_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6708e03a1d7b"
   },
   "source": [
    "## Example: Grounding with Google Maps\n",
    "\n",
    "You can also use Google Maps data for grounding with Gemini. See the [documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/grounding/grounding-with-google-maps) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ebfa54b6b14e"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "\n",
       "**Retrieval Queries:** ['best vegetarian restaurants Las Vegas', 'vegetarian friendly restaurants Las Vegas']\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "google_maps_tool = Tool(google_maps=GoogleMaps())\n",
    "\n",
    "PROMPT = \"Recommend some good vegetarian food in Las Vegas.\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=[\n",
    "        PROMPT,\n",
    "    ],\n",
    "    config=GenerateContentConfig(\n",
    "        system_instruction=\"You are a helpful assistant that provides information about locations. You have access to map data and can answer questions about distances, directions, and points of interest.\",\n",
    "        tools=[google_maps_tool],\n",
    "        # Optional: Set Latitude and Longitude for the Google Maps tool\n",
    "        tool_config=ToolConfig(\n",
    "            retrieval_config=RetrievalConfig(\n",
    "                lat_lng=LatLng(latitude=36.1699, longitude=-115.1398)\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77f0800f8762"
   },
   "source": [
    "## Example: Grounding with custom documents and data\n",
    "\n",
    "In this example, you'll compare LLM responses with no grounding with responses that are grounded in the [results of a search app in Vertex AI Search](https://cloud.google.com/generative-ai-app-builder/docs/create-datastore-ingest).\n",
    "\n",
    "The data store will contain internal documents from a fictional bank, Cymbal Bank. These documents aren't available on the public internet, so the Gemini model won't have any information about them by default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1b308548c68b"
   },
   "source": [
    "### Creating a data store in Vertex AI Search\n",
    "\n",
    "In this example, you'll use a Google Cloud Storage bucket with a few sample internal documents for our bank. There's some docs about booking business travel, strategic plan for this Fiscal Year and HR docs describing the different jobs available in the company.\n",
    "\n",
    "Follow the tutorial steps in the Vertex AI Search documentation to:\n",
    "\n",
    "1. [Create a data store with unstructured data](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#unstructured-data) that loads in documents from the GCS folder `gs://cloud-samples-data/gen-app-builder/search/cymbal-bank-employee`.\n",
    "2. [Create a search app](https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app) that is attached to that data store. You should also enable the **Enterprise edition features** so that you can search indexed records within the data store.\n",
    "\n",
    "**Note:** The data store must be in the same project that you are using for Gemini.\n",
    "\n",
    "You can also follow this notebook to do it with code. [Create a Vertex AI Search Datastore and App](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/search/create_datastore_and_search.ipynb)\n",
    "\n",
    "Once you've created a data store, obtain the App ID and input it below.\n",
    "\n",
    "Note: You will need to wait for data ingestion to finish before using a data store with grounding. For more information, see [create a data store](https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fcd767476241"
   },
   "outputs": [],
   "source": [
    "VERTEX_AI_SEARCH_PROJECT_ID = PROJECT_ID  # @param {type: \"string\"}\n",
    "VERTEX_AI_SEARCH_REGION = \"global\"  # @param {type: \"string\"}\n",
    "# Replace this with your App (Engine) ID from Vertex AI Search\n",
    "VERTEX_AI_SEARCH_APP_ID = \"cymbal-bank-onboarding\"  # @param {type: \"string\"}\n",
    "\n",
    "VERTEX_AI_SEARCH_ENGINE_NAME = f\"projects/{VERTEX_AI_SEARCH_PROJECT_ID}/locations/{VERTEX_AI_SEARCH_REGION}/collections/default_collection/engines/{VERTEX_AI_SEARCH_APP_ID}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccc156676e0a"
   },
   "source": [
    "Now you can ask a question about the company culture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9c1e1b1743bd"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What is the company culture like?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f365681544bb"
   },
   "source": [
    "### Text generation without grounding\n",
    "\n",
    "Make a prediction request to the LLM with no grounding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "299818ae71e9"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To give you an accurate answer, I need to know *which* company you're asking about! Company culture varies wildly from one organization to the next.\n",
       "\n",
       "However, if you're asking generally, when people talk about company culture, they're typically referring to the shared values, beliefs, attitudes, practices, and behaviors that characterize an organization and its employees.\n",
       "\n",
       "**To give you a good answer about a *specific* company, I'd look for information on aspects like:**\n",
       "\n",
       "*   **Work Environment:** Is it fast-paced, relaxed, formal, informal, collaborative, competitive, innovative, structured, flexible?\n",
       "*   **Values and Priorities:** What does the company emphasize? (e.g., customer satisfaction, employee well-being, innovation, growth, social impact, ethics, profit, transparency).\n",
       "*   **Communication Style:** Is communication open and transparent, or more hierarchical? Is feedback encouraged?\n",
       "*   **Leadership Style:** Are leaders hands-on or hands-off? Supportive or demanding?\n",
       "*   **Team Dynamics:** Do teams work closely together, or is work more individual? Is there a sense of camaraderie?\n",
       "*   **Work-Life Balance:** Is it generally good, or are long hours expected? Is there flexibility?\n",
       "*   **Growth and Development:** Are there opportunities for learning, training, and career advancement? Is mentorship common?\n",
       "*   **Social Aspects:** Are there team events, social gatherings, or a strong sense of community?\n",
       "*   **Diversity & Inclusion:** How committed is the company to creating an inclusive environment?\n",
       "*   **Perks and Benefits:** While not *culture* itself, these can reflect company values (e.g., generous PTO, wellness programs, unique office spaces).\n",
       "\n",
       "**Once you tell me the company, I can try to find information from various sources like:**\n",
       "\n",
       "*   Company websites (careers pages, \"about us\")\n",
       "*   Employee review sites (Glassdoor, Indeed, LinkedIn)\n",
       "*   News articles and press releases\n",
       "*   Social media presence\n",
       "\n",
       "**Please tell me which company you're interested in!**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=PROMPT,\n",
    ")\n",
    "\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "073f2ec42ff6"
   },
   "source": [
    "### Text generation grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `grounding.VertexAISearch()` to instruct the LLM to first perform a search within your search app, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "d4c5d53a37b4"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Please specify which company you are asking about so I can provide information about its company culture.\n",
       "\n",
       "----\n",
       "## Grounding Sources\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vertex_ai_search_tool = Tool(\n",
    "    retrieval=Retrieval(\n",
    "        vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "    )\n",
    ")\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=MODEL_ID,\n",
    "    contents=\"What is the company culture like?\",\n",
    "    config=GenerateContentConfig(tools=[vertex_ai_search_tool]),\n",
    ")\n",
    "\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e3f985c704cd"
   },
   "source": [
    "Note that the response without grounding doesn't have any context about what company we are asking about. Whereas the response that was grounded in Vertex AI Search results contains information from the documents provided, along with citations of the information.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>⚠️ Important notes:</b><br>\n",
    "<br>\n",
    "<b>If you get an error when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;In order for this sample notebook to work with data store in Vertex AI Search,<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;you'll need to create a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_data_store\">data store</a> <b>and</b> a <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/try-enterprise-search#create_a_search_app\">search app</a> associated with it in Vertex AI Search.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;If you only create a data store, the previous request will return errors when making queries against the data store.\n",
    "<br><br>\n",
    "<b>If you get an empty response when running the previous cell:</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;You will need to wait for data ingestion to finish before using a data store with grounding.<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;For more information, see <a href=\"https://cloud.google.com/generative-ai-app-builder/docs/create-data-store-es\">create a data store</a>.\n",
    "</div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "54562717e2a4",
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## Example: Grounded chat responses\n",
    "\n",
    "You can also use grounding when using chat conversations in Vertex AI. In this example, you'll compare LLM responses with no grounding with responses that are grounded in the results of a Google Search and a data store in Vertex AI Search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "490cf1ed3399"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"What are managed datasets in Vertex AI?\"\n",
    "PROMPT_FOLLOWUP = \"What types of data can I use?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b59783e4f1ce"
   },
   "source": [
    "### Chat session grounded in Google Search results\n",
    "\n",
    "Now you can add the `tools` keyword arg with a Tool of `GoogleSearch` to instruct the chat model to first perform a Google Search with the prompt, then construct an answer based on the web search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "58edb2bd860f"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> What are managed datasets in Vertex AI?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Managed datasets in Vertex AI are a centralized and structured way to manage, prepare, and access machine learning data for training and serving models [1]. They are integrated within the Vertex AI framework, providing a single source of truth for your ML data [2][1]. While optional for custom models, managed datasets are a requirement for AutoML and Gemini training [2][3].\n",
       "\n",
       "Key features and benefits of managed datasets in Vertex AI include:\n",
       "*   **Centralized Management** They offer a central location to organize and manage your datasets within Vertex AI, simplifying dataset organization, access, and version control [2][1][4].\n",
       "*   **Data Preparation and Annotation** You can easily create labels and multiple annotation sets, as well as create tasks for human labeling using integrated data labeling tools [2][5][4]. Vertex AI also provides automated data preprocessing capabilities like data cleansing, transformation, and encoding, which reduces manual effort [1].\n",
       "*   **Data Splitting** Vertex AI can automatically split your data into training, validation, and test sets based on specified fractions, filters, predefined splits, or timestamps [5][4].\n",
       "*   **Lineage Tracking** Managed datasets allow you to track the lineage of your data to the models trained on it, which is important for governance and iterative development [2][5][4].\n",
       "*   **Model Performance Comparison** You can compare the performance of different AI models by training both AutoML and custom models using the same datasets [2][5].\n",
       "*   **Statistics and Visualizations** Vertex AI can automatically generate statistics and visualizations for the data within a managed dataset, aiding in exploratory data analysis [2][4].\n",
       "*   **Versioning** Managed datasets support versioning, enabling you to track changes over time and revert to previous versions if needed [1][6][4].\n",
       "*   **Integration with Training Pipelines** They can be seamlessly integrated into model training pipelines, allowing direct utilization of datasets for training without additional setup [1].\n",
       "\n",
       "Managed datasets support various data types, including image, text, video, and tabular data, and they can be created via the Google Cloud Platform (GCP) console or Vertex AI APIs [2][5][1]. Data can be imported from local files, Cloud Storage buckets, or BigQuery tables [1].\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [promevo.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQETk640Bcnbfzrzry5TSVV9JTGuiTY1BKOkcM3xPWiN2dzjkPMNyUz5DFRS74CCmuTM9voAB-6AYy8DvOjoi1esjeiw150jDlj1MOi-477djMAPiDoUlxQlpqcgwgxhw2WbMnOyRaKnz43r9_u1rg6Yp1RM)\n",
       "2. [medium.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEUZCuvDtJotLZfL2rfJjeLMwEwpl0WX87xXyN6gkrQHw1ZPxuSebRKBm_yL7JwDPxFGHingUiGWIFh-xtxSobvfa9ozYKnJjTZBpJaMdtw9zGRv2eptK9r5Jn9pEM4jFlGq2OJ0DwE9PtZKD5WAJOWS6xlfEqDztHgqmMDZwIctl9IwUpopI81L3LNIRgkzyivEblQGT--ZvE7CHHSk3hyv6-H69bJI6xTdw==)\n",
       "3. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGJ0F6B4YFZXxpetPx63rSnLX-05en1ElPN-TSXno0j-7vuoVe2UnCMLkqFY9Vxm9B4ZSvucvm7e9vdxAa_MPt7j1Viw75LPIIenvUmSCsW2orTuwCzvs9eZ6Ee-nM3vki8zU1nSNZzUkHoNS6gzh-jVfv-R3R1Eznr)\n",
       "4. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFketmcdoINnLHMCZLfZ3dYPW31O-rZTdZaqjvTKwvQszaXm7Flz-9H4e9C2pwIfWj9QgjzQrj_QrvZyLcQmcaq1MJ91czG_sXyBHgnrb0J7CZP3QwM1P-F4qMKY3RIrbUSozSgIH2QLlvA7j0Ke1PwSvgNbd4YOPqzA50GWVNYUkVsFY--Ot7LPSI=)\n",
       "5. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQFaRI0G0uZDDckyCZpW2l7ju-yRBjpnPQPWnbrbOJx9mIQksBCd1Y3qaCWpuVwr-k2v9FZVMfXQ19r2Ep1ngT2IHZoCvynx04iMx1dYegJqNtE7sSZCeHn6E7z1P05433KlWxlggRM94ypM0AuQIGc3HBZPc2Np1tgrAXZ-_e3DqsXheReYaWc=)\n",
       "6. [promevo.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGABUHtl94w8VRdUAeF_103ThjzV_POVIbWMcOXb2F3QMPrTecyHg1BjBYsF1wjk3VfVVamtGajvZYUjVpmSvk3F4Mt_3L7oTZeZJAmJDnsOZR3oNu7g1pKsv9pTTCBnnMQI9cBxnOpX7OWkv6SPqO9)\n",
       "\n",
       "**Web Search Queries:** ['managed datasets Vertex AI', 'Vertex AI managed dataset features', 'benefits of managed datasets in Vertex AI']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEIgsDCphzOfrQG2DcJkDn2ZDO-EZBel4ws8X68eigZoaSPTxpogJ7eySLcLVAu-bdYKc7jYTMiqqzWOjab0wDvrf1L-CoMnXoU1bjPoHykyXYb55FAX26vwRx4TOthB030MMazyZytkf-N5n4s11UBZvTHLU04Yk5vBCR7qCIpDl5cK7KGFvwX5UCvShV4VfQgu3qKfDo9jTk5FpzAXew0VkIdgreEOHRr6Mcz\">benefits of managed datasets in Vertex AI</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQErCpu7MaxwWyMXK2_bo8_5ZExo1BZaiFrKDMPP112S5lp0iSNu88HvJ2IBPdkFWRKuZ8DPs7JfhEzpLnuUsGHo6UJyrJLYaEShdpx4R7sEd8M_VTzg4CnPnVvdrYVKoPLc1x6perW9Z9di9NZXkPLy8VMHXp5kUgjpCU9HUVXPhZVGIhC53zTfe98qYT9wM4ucr0yWaMvQeD_RqKdr\">managed datasets Vertex AI</a>\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQF9QPirO7ltytWSazm0LossPcqFE-ri2G7iMdnFZNJuQZoPZVIJRMPOK4ftAhPD0IEsXfJwNbMOkO4Tmzky1B-L7Rj-wMOZbgN_Te46FPQ7vVAwiDXYlFKUhwuTDsr7EKr0BWAuFmWzgVsUVDV6mhdAuk_HiJ2hbeyCl8M6Rd8da8c4oLjdwz52VAshnebejimJ3IZccoWtkbntwVrnXJX8Qktgbhk=\">Vertex AI managed dataset features</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "---\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## Follow-up Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> What types of data can I use?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Vertex AI managed datasets support four primary data types: image, tabular, text, and video [1][2]. These datasets can be created and managed directly within the Google Cloud Console or via Vertex AI APIs, and data can be imported from local files, Cloud Storage buckets, or BigQuery tables [3].\n",
       "\n",
       "Here's a breakdown of each data type and its common use cases:\n",
       "\n",
       "*   **Image Datasets** Image datasets are used for various computer vision tasks.\n",
       "    *   **Use Cases:** Image classification (identifying items within an image), object detection (locating items in an image), and image segmentation (assigning labels to pixel-level regions) [1][3][2].\n",
       "    *   **Supported Formats for Training Data:** JPEG, GIF, PNG, BMP, ICO (with a maximum file size of 30MB) [3].\n",
       "    *   **Supported Formats for Prediction Data:** JPEG, GIF, PNG, WEBP, BMP, TIFF, ICO (with a maximum file size of 1.5MB) [3].\n",
       "\n",
       "*   **Tabular Datasets** Tabular datasets consist of structured data organized in rows and columns.\n",
       "    *   **Use Cases:** Classification, regression, and forecasting models [3]. These are ideal for analyzing structured data such as customer information or financial records [3].\n",
       "    *   **Data Sources:** Can be uploaded as CSV files or connected directly from BigQuery tables [4][3][2]. Vertex AI allows for defining the schema, including column names and data types, which assists in automated preprocessing [3].\n",
       "\n",
       "*   **Text Datasets** Text datasets contain written text.\n",
       "    *   **Use Cases:** Text classification (assigning one or more labels to a document), sentiment analysis (understanding the emotional tone of text), and natural language processing (NLP) tasks like text entity extraction and content generation [1][3][2].\n",
       "\n",
       "*   **Video Datasets** Video datasets comprise video content.\n",
       "    *   **Use Cases:** Video classification (labeling entire videos, shots, or frames), action recognition (identifying specific actions in video clips), and object tracking (following specific objects within a video) [1][3].\n",
       "\n",
       "It's important to note that Vertex AI datasets reference your original data, rather than duplicating it [4]. For custom training, managed datasets are optional, but they are a requirement for AutoML and Gemini training [3].\n",
       "\n",
       "----\n",
       "## Grounding Sources\n",
       "### Grounding Chunks\n",
       "1. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGcDRwwpke5BWuM1ZE9CT5k6kpiQKR4IGtaf5Wx5Gg1l6wVPDWx7yZrbyxNv92MpocHJhQG6wIit6Zv6tm5wwIVKFmiWHWqbNhj7DzTkr7pNA4vx61lk-DYAhbDC8Aj-0bJgEdPgHvn9pTNW8VrFMO55MBbQAX2NFG7JRbI0IWBexhnZN9wXvO3rDNQkVuN1SBgfleYcB7HnxY8Zz6zaRJX2w==)\n",
       "2. [youtube.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGRbY268DFkFt2Dqt-kPHA01ZffU1TS_Fh76bw1yEQ_TZSzYWt2suzs5sZBy4einbZtiZX1OlHIqo2FSZ39Tu-Pj5U8KEUjGBCK1vMhWNNuCKfnsV_2pfPIVE3DgurMR1JZIzF8Iw==)\n",
       "3. [promevo.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQHdW3ZTaFSPsx3HwEt-Ff8THR_6jk4M2kvs6QUx7mw_Ajmo6l4I2ioG7OTPGu2cPSOxVHjRCsZEv1uxa89H_f5k_lkwuxJO0Ayf0cGzBixb2dkkoLkc41mrs9PjyAHhn6fZrDVcIwaq_WqRJYMjZ2CTQd0=)\n",
       "4. [google.com](https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQGKJInz-gmB8DgA3YU65b1bAMekEexFi2TzHlir9AnSPVyW0IsTq94WWQaQ8b1A8ziJY9whdWXdBoO8wN6D0qkgP_9IbS55KTpaP89UbEvE-kFFQ502e4WDh5JT8J4nV4s2hUIGN_LML3gOUoGd-cENlC5pk-nKvCH2qVVNkJ93O8RQz2loGjZh)\n",
       "\n",
       "**Web Search Queries:** ['Vertex AI managed datasets supported data types']\n",
       "\n",
       "**Search Entry Point:**\n",
       "<style>\n",
       ".container {\n",
       "  align-items: center;\n",
       "  border-radius: 8px;\n",
       "  display: flex;\n",
       "  font-family: Google Sans, Roboto, sans-serif;\n",
       "  font-size: 14px;\n",
       "  line-height: 20px;\n",
       "  padding: 8px 12px;\n",
       "}\n",
       ".chip {\n",
       "  display: inline-block;\n",
       "  border: solid 1px;\n",
       "  border-radius: 16px;\n",
       "  min-width: 14px;\n",
       "  padding: 5px 16px;\n",
       "  text-align: center;\n",
       "  user-select: none;\n",
       "  margin: 0 8px;\n",
       "  -webkit-tap-highlight-color: transparent;\n",
       "}\n",
       ".carousel {\n",
       "  overflow: auto;\n",
       "  scrollbar-width: none;\n",
       "  white-space: nowrap;\n",
       "  margin-right: -12px;\n",
       "}\n",
       ".headline {\n",
       "  display: flex;\n",
       "  margin-right: 4px;\n",
       "}\n",
       ".gradient-container {\n",
       "  position: relative;\n",
       "}\n",
       ".gradient {\n",
       "  position: absolute;\n",
       "  transform: translate(3px, -9px);\n",
       "  height: 36px;\n",
       "  width: 9px;\n",
       "}\n",
       "@media (prefers-color-scheme: light) {\n",
       "  .container {\n",
       "    background-color: #fafafa;\n",
       "    box-shadow: 0 0 0 1px #0000000f;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #1f1f1f;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #ffffff;\n",
       "    border-color: #d2d2d2;\n",
       "    color: #5e5e5e;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #f2f2f2;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #d8d8d8;\n",
       "    border-color: #b6b6b6;\n",
       "  }\n",
       "  .logo-dark {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #fafafa 15%, #fafafa00 100%);\n",
       "  }\n",
       "}\n",
       "@media (prefers-color-scheme: dark) {\n",
       "  .container {\n",
       "    background-color: #1f1f1f;\n",
       "    box-shadow: 0 0 0 1px #ffffff26;\n",
       "  }\n",
       "  .headline-label {\n",
       "    color: #fff;\n",
       "  }\n",
       "  .chip {\n",
       "    background-color: #2c2c2c;\n",
       "    border-color: #3c4043;\n",
       "    color: #fff;\n",
       "    text-decoration: none;\n",
       "  }\n",
       "  .chip:hover {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:focus {\n",
       "    background-color: #353536;\n",
       "  }\n",
       "  .chip:active {\n",
       "    background-color: #464849;\n",
       "    border-color: #53575b;\n",
       "  }\n",
       "  .logo-light {\n",
       "    display: none;\n",
       "  }\n",
       "  .gradient {\n",
       "    background: linear-gradient(90deg, #1f1f1f 15%, #1f1f1f00 100%);\n",
       "  }\n",
       "}\n",
       "</style>\n",
       "<div class=\"container\">\n",
       "  <div class=\"headline\">\n",
       "    <svg class=\"logo-light\" width=\"18\" height=\"18\" viewBox=\"9 9 35 35\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M42.8622 27.0064C42.8622 25.7839 42.7525 24.6084 42.5487 23.4799H26.3109V30.1568H35.5897C35.1821 32.3041 33.9596 34.1222 32.1258 35.3448V39.6864H37.7213C40.9814 36.677 42.8622 32.2571 42.8622 27.0064V27.0064Z\" fill=\"#4285F4\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 43.8555C30.9659 43.8555 34.8687 42.3195 37.7213 39.6863L32.1258 35.3447C30.5898 36.3792 28.6306 37.0061 26.3109 37.0061C21.8282 37.0061 18.0195 33.9811 16.6559 29.906H10.9194V34.3573C13.7563 39.9841 19.5712 43.8555 26.3109 43.8555V43.8555Z\" fill=\"#34A853\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M16.6559 29.8904C16.3111 28.8559 16.1074 27.7588 16.1074 26.6146C16.1074 25.4704 16.3111 24.3733 16.6559 23.3388V18.8875H10.9194C9.74388 21.2072 9.06992 23.8247 9.06992 26.6146C9.06992 29.4045 9.74388 32.022 10.9194 34.3417L15.3864 30.8621L16.6559 29.8904V29.8904Z\" fill=\"#FBBC05\"/>\n",
       "      <path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M26.3109 16.2386C28.85 16.2386 31.107 17.1164 32.9095 18.8091L37.8466 13.8719C34.853 11.082 30.9659 9.3736 26.3109 9.3736C19.5712 9.3736 13.7563 13.245 10.9194 18.8875L16.6559 23.3388C18.0195 19.2636 21.8282 16.2386 26.3109 16.2386V16.2386Z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <svg class=\"logo-dark\" width=\"18\" height=\"18\" viewBox=\"0 0 48 48\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "      <circle cx=\"24\" cy=\"23\" fill=\"#FFF\" r=\"22\"/>\n",
       "      <path d=\"M33.76 34.26c2.75-2.56 4.49-6.37 4.49-11.26 0-.89-.08-1.84-.29-3H24.01v5.99h8.03c-.4 2.02-1.5 3.56-3.07 4.56v.75l3.91 2.97h.88z\" fill=\"#4285F4\"/>\n",
       "      <path d=\"M15.58 25.77A8.845 8.845 0 0 0 24 31.86c1.92 0 3.62-.46 4.97-1.31l4.79 3.71C31.14 36.7 27.65 38 24 38c-5.93 0-11.01-3.4-13.45-8.36l.17-1.01 4.06-2.85h.8z\" fill=\"#34A853\"/>\n",
       "      <path d=\"M15.59 20.21a8.864 8.864 0 0 0 0 5.58l-5.03 3.86c-.98-2-1.53-4.25-1.53-6.64 0-2.39.55-4.64 1.53-6.64l1-.22 3.81 2.98.22 1.08z\" fill=\"#FBBC05\"/>\n",
       "      <path d=\"M24 14.14c2.11 0 4.02.75 5.52 1.98l4.36-4.36C31.22 9.43 27.81 8 24 8c-5.93 0-11.01 3.4-13.45 8.36l5.03 3.85A8.86 8.86 0 0 1 24 14.14z\" fill=\"#EA4335\"/>\n",
       "    </svg>\n",
       "    <div class=\"gradient-container\"><div class=\"gradient\"></div></div>\n",
       "  </div>\n",
       "  <div class=\"carousel\">\n",
       "    <a class=\"chip\" href=\"https://vertexaisearch.cloud.google.com/grounding-api-redirect/AUZIYQEl6I7cR1Ro0F8asfaC7HaWfl8zcGWknFw42ZVHsa48z2dzF5wDXEYDT5zlm1nioUmI5yyN8nBbz9OON0mNGRcxK36S_Tq0kfDttws_fN9SgxAiyM844LGWzJ4vZeWVnJiQzWCZXWwr5CjfDAL_JJxxH4pGiYSIjzRkI1tRyc-Y8q72lXz4En3ctBPyoY9ha1juIvk7BXQ1GbbZ2Hy4QoG9mn_mFqNWInb2dro7VxK7Ejs=\">Vertex AI managed datasets supported data types</a>\n",
       "  </div>\n",
       "</div>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(tools=[Tool(google_search=GoogleSearch())]),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "print_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87be7f661f14"
   },
   "source": [
    "### Chat session grounded in Vertex AI Search results\n",
    "\n",
    "Now we can add the `tools` keyword arg with a grounding tool of `VertexAISearch` to instruct the chat session to first perform a search within your custom search app, then construct an answer based on the relevant documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "8fdad0c3f1f3"
   },
   "outputs": [],
   "source": [
    "PROMPT = \"How do I book business travel?\"\n",
    "PROMPT_FOLLOWUP = \"Give me more details.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1a824202a8f0"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Prompt"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> How do I book business travel?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ClientError",
     "evalue": "404 NOT_FOUND. {'error': {'code': 404, 'message': 'We were unable to find an engine to service the request. This may be an intermittent issue -- please try again in 3-5 minutes. If the issue persists, please contact support.', 'status': 'NOT_FOUND'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mClientError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m## Prompt\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m display(Markdown(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mPROMPT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 16\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPROMPT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m print_grounding_data(response)\n\u001b[1;32m     19\u001b[0m display(Markdown(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m---\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/chats.py:254\u001b[0m, in \u001b[0;36mChat.send_message\u001b[0;34m(self, message, config)\u001b[0m\n\u001b[1;32m    249\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    250\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessage must be a valid part type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    251\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;241m.\u001b[39mPartUnionDict\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(message)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    252\u001b[0m   )\n\u001b[1;32m    253\u001b[0m input_content \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mt_content(message)\n\u001b[0;32m--> 254\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_modules\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_curated_history\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_content\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m model_output \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    260\u001b[0m     [response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent]\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcandidates[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m automatic_function_calling_history \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    265\u001b[0m     response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mautomatic_function_calling_history\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    268\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/models.py:5203\u001b[0m, in \u001b[0;36mModels.generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   5201\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m remaining_remote_calls_afc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   5202\u001b[0m   i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 5203\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5204\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparsed_config\u001b[49m\n\u001b[1;32m   5205\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5207\u001b[0m   function_map \u001b[38;5;241m=\u001b[39m _extra_utils\u001b[38;5;241m.\u001b[39mget_function_map(parsed_config)\n\u001b[1;32m   5208\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m function_map:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/models.py:3985\u001b[0m, in \u001b[0;36mModels._generate_content\u001b[0;34m(self, model, contents, config)\u001b[0m\n\u001b[1;32m   3982\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mconvert_to_dict(request_dict)\n\u001b[1;32m   3983\u001b[0m request_dict \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mencode_unserializable_types(request_dict)\n\u001b[0;32m-> 3985\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_api_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3986\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[1;32m   3987\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3989\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[1;32m   3990\u001b[0m     config, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould_return_http_response\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   3991\u001b[0m ):\n\u001b[1;32m   3992\u001b[0m   return_value \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mGenerateContentResponse(sdk_http_response\u001b[38;5;241m=\u001b[39mresponse)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1388\u001b[0m, in \u001b[0;36mBaseApiClient.request\u001b[0;34m(self, http_method, path, request_dict, http_options)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m   1379\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1380\u001b[0m     http_method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1383\u001b[0m     http_options: Optional[HttpOptionsOrDict] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1384\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SdkHttpResponse:\n\u001b[1;32m   1385\u001b[0m   http_request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request(\n\u001b[1;32m   1386\u001b[0m       http_method, path, request_dict, http_options\n\u001b[1;32m   1387\u001b[0m   )\n\u001b[0;32m-> 1388\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1389\u001b[0m   response_body \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1390\u001b[0m       response\u001b[38;5;241m.\u001b[39mresponse_stream[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mresponse_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1391\u001b[0m   )\n\u001b[1;32m   1392\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m SdkHttpResponse(headers\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders, body\u001b[38;5;241m=\u001b[39mresponse_body)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1224\u001b[0m, in \u001b[0;36mBaseApiClient._request\u001b[0;34m(self, http_request, http_options, stream)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     retry \u001b[38;5;241m=\u001b[39m tenacity\u001b[38;5;241m.\u001b[39mRetrying(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mretry_kwargs)\n\u001b[1;32m   1222\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retry(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request_once, http_request, stream)  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[0;32m-> 1224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:477\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 477\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:378\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[0;34m(self, retry_state)\u001b[0m\n\u001b[1;32m    376\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[0;32m--> 378\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:420\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[0;34m(rs)\u001b[0m\n\u001b[1;32m    418\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[1;32m    419\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[0;32m--> 420\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:187\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[0;32m--> 187\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_attempt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tenacity/__init__.py:480\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 480\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[1;32m    482\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/_api_client.py:1201\u001b[0m, in \u001b[0;36mBaseApiClient._request_once\u001b[0;34m(self, http_request, stream)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1194\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_httpx_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[1;32m   1195\u001b[0m       method\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m   1196\u001b[0m       url\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39murl,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1199\u001b[0m       timeout\u001b[38;5;241m=\u001b[39mhttp_request\u001b[38;5;241m.\u001b[39mtimeout,\n\u001b[1;32m   1200\u001b[0m   )\n\u001b[0;32m-> 1201\u001b[0m   \u001b[43merrors\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAPIError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1202\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[1;32m   1203\u001b[0m       response\u001b[38;5;241m.\u001b[39mheaders, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response\u001b[38;5;241m.\u001b[39mtext]\n\u001b[1;32m   1204\u001b[0m   )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/errors.py:121\u001b[0m, in \u001b[0;36mAPIError.raise_for_response\u001b[0;34m(cls, response)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m   response_json \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mbody_segments[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m, {})\n\u001b[0;32m--> 121\u001b[0m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/google/genai/errors.py:146\u001b[0m, in \u001b[0;36mAPIError.raise_error\u001b[0;34m(cls, status_code, response_json, response)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Raises an appropriate APIError subclass based on the status code.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m  APIError: For other error status codes.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;241m400\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m--> 146\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;241m500\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m status_code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m600\u001b[39m:\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ServerError(status_code, response_json, response)\n",
      "\u001b[0;31mClientError\u001b[0m: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'We were unable to find an engine to service the request. This may be an intermittent issue -- please try again in 3-5 minutes. If the issue persists, please contact support.', 'status': 'NOT_FOUND'}}"
     ]
    }
   ],
   "source": [
    "chat = client.chats.create(\n",
    "    model=MODEL_ID,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[\n",
    "            Tool(\n",
    "                retrieval=Retrieval(\n",
    "                    vertex_ai_search=VertexAISearch(engine=VERTEX_AI_SEARCH_ENGINE_NAME)\n",
    "                )\n",
    "            )\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "display(Markdown(\"## Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT}\"))\n",
    "response = chat.send_message(PROMPT)\n",
    "print_grounding_data(response)\n",
    "\n",
    "display(Markdown(\"---\\n\"))\n",
    "\n",
    "display(Markdown(\"## Follow-up Prompt\"))\n",
    "display(Markdown(f\"> {PROMPT_FOLLOWUP}\"))\n",
    "response = chat.send_message(PROMPT_FOLLOWUP)\n",
    "print_grounding_data(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "intro-grounding-gemini.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
