{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05",
      "metadata": {
        "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29cdff1-a6b8-475b-dc4b-0bcc4dd5faf0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Operation \"operations/acat.p2-749926295422-b9a57711-db38-4592-8bc4-0b7090ac30c2\" finished successfully.\n"
          ]
        }
      ],
      "source": [
        "!gcloud services enable aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
      "metadata": {
        "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
        "outputId": "971b551f-92dd-41f4-cf74-cd035bf39f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                 NETWORK  DIRECTION  PRIORITY  ALLOW     DENY  DISABLED\n",
            "allow-imc-streamlit  default  INGRESS    1000      tcp:8501        False\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "gcloud compute firewall-rules create allow-imc-streamlit \\\n",
        "    --direction=INGRESS \\\n",
        "    --priority=1000 \\\n",
        "    --network=default \\\n",
        "    --action=ALLOW \\\n",
        "    --rules=tcp:8501 \\\n",
        "    --source-ranges=0.0.0.0/0 2> /dev/null\n",
        "\n",
        "gcloud compute firewall-rules list --filter name='allow-imc-streamlit' 2> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1",
      "metadata": {
        "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14519cbd-08c4-4309-9d04-688ee238859c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/9.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/9.0 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m154.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m257.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m122.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "45dc014c-8d00-493c-b061-b76a0612b749",
      "metadata": {
        "id": "45dc014c-8d00-493c-b061-b76a0612b749",
        "outputId": "8aacf462-6efc-4291-d160-e3d15aab5e1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing gemini-chat.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile gemini-chat.py\n",
        "import streamlit as st\n",
        "import vertexai, google.auth\n",
        "from vertexai.generative_models import (\n",
        "    GenerativeModel,\n",
        "    GenerationConfig,\n",
        "    Part\n",
        ")\n",
        "\n",
        "paises_data = {\n",
        "    \"Polonia\": {\n",
        "        \"capital\": \"Varsovia\",\n",
        "        \"population\": 38_750_000,\n",
        "        \"area_km2\": 312_696,\n",
        "        \"currency\": \"Złoty (PLN)\",\n",
        "        \"eu_member\": True,\n",
        "        \"language\": \"Polish\"\n",
        "    },\n",
        "    \"Alemania\": {\n",
        "        \"capital\": \"Berlin\",\n",
        "        \"population\": 84_120_000,\n",
        "        \"area_km2\": 357_022,\n",
        "        \"currency\": \"Euro (EUR)\",\n",
        "        \"eu_member\": True,\n",
        "        \"language\": \"German\"\n",
        "    },\n",
        "    \"Ucrania\": {\n",
        "        \"capital\": \"Kyiv\",\n",
        "        \"population\": 35_660_000,\n",
        "        \"area_km2\": 603_628,\n",
        "        \"currency\": \"Hryvnia (UAH)\",\n",
        "        \"eu_member\": False,\n",
        "        \"language\": \"Ukrainian\"\n",
        "    }\n",
        "}\n",
        "\n",
        "def pais_info(pais: str):\n",
        "  info = paises_data.get(pais)\n",
        "\n",
        "  if not info:\n",
        "    return {\"error\" : \"Pais no encontrado\",\n",
        "            \"paises disponibles\":list(paises_data.keys())\n",
        "    }\n",
        "\n",
        "  return {\n",
        "        \"pais\": pais,\n",
        "        \"data\": info\n",
        "    }\n",
        "\n",
        "herramientas_mapeo = {\"pais_info\" : pais_info}\n",
        "\n",
        "# --- Generar Modelo\n",
        "credentials, project_id = google.auth.default()\n",
        "vertexai.init(project=project_id, location=\"us-central1\")\n",
        "\n",
        "context = \"\"\"\n",
        "You are an expert in geography, history and politics of Central Europe.\n",
        "You can answer general questions, but when population data is needed,\n",
        "you must call the function numero_habitantes. When asked about other countries,\n",
        "say you are not qualified to answer questions about other countries.\n",
        "\"\"\"\n",
        "model_name = \"gemini-2.5-flash-lite\"\n",
        "model = GenerativeModel(model_name, system_instruction = context)\n",
        "\n",
        "\n",
        "# --- Web UI con Streamlit\n",
        "st.title(\"Chat con Gemini\")\n",
        "if \"chat\" not in st.session_state:\n",
        "    st.session_state.chat = model.start_chat()\n",
        "prompt = st.text_input(\"Ask me about Central Europe\")\n",
        "if st.button(\"Submit\") and prompt.strip():\n",
        "    st.chat_message(\"user\").write(prompt)\n",
        "\n",
        "    try:\n",
        "        response = st.session_state.chat.send_message(prompt)\n",
        "        part = response.candidates[0].content.parts[0]\n",
        "\n",
        "        if part.function_call:\n",
        "            fn_name = part.function_call.name\n",
        "            fn_args = dict(part.function_call.args)\n",
        "\n",
        "            if fn_name in herramientas_mapeo:\n",
        "                tool_result = herramientas_mapeo[fn_name](**fn_args)\n",
        "\n",
        "                response = st.session_state.chat.send_message(\n",
        "                    Part.from_function_response(\n",
        "                        name=fn_name,\n",
        "                        response=tool_result,\n",
        "                    )\n",
        "                )\n",
        "\n",
        "        st.chat_message(\"assistant\").write(response.text)\n",
        "\n",
        "    except Exception as e:\n",
        "        st.error(f\"Error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
      "metadata": {
        "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
        "outputId": "25b7cae6-a3a5-47d2-9b1d-a8bc87012d1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.6.30.94:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run gemini-chat.py --server.port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c3c700-6abf-41db-8ab5-1920808b48dd",
      "metadata": {
        "id": "89c3c700-6abf-41db-8ab5-1920808b48dd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m137",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}