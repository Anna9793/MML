{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05",
      "metadata": {
        "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05"
      },
      "outputs": [],
      "source": [
        "!gcloud services enable aiplatform.googleapis.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
      "metadata": {
        "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
        "outputId": "971b551f-92dd-41f4-cf74-cd035bf39f47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME                 NETWORK  DIRECTION  PRIORITY  ALLOW     DENY  DISABLED\n",
            "allow-imc-streamlit  default  INGRESS    1000      tcp:8501        False\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "gcloud compute firewall-rules create allow-imc-streamlit \\\n",
        "    --direction=INGRESS \\\n",
        "    --priority=1000 \\\n",
        "    --network=default \\\n",
        "    --action=ALLOW \\\n",
        "    --rules=tcp:8501 \\\n",
        "    --source-ranges=0.0.0.0/0 2> /dev/null\n",
        "\n",
        "gcloud compute firewall-rules list --filter name='allow-imc-streamlit' 2> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1",
      "metadata": {
        "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45dc014c-8d00-493c-b061-b76a0612b749",
      "metadata": {
        "id": "45dc014c-8d00-493c-b061-b76a0612b749",
        "outputId": "0a8a7dfb-6a9b-4460-8510-dad28060ae30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting gemini-chat.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile gemini-chat.py\n",
        "import streamlit as st\n",
        "import json\n",
        "import vertexai, google.auth\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig, Part\n",
        "\n",
        "def numero_habitantes(pais: str):\n",
        "    if pais == \"Polonia\":\n",
        "        return {\"pais\": \"Polonia\", \"habitantes\": 38_750_000}\n",
        "    elif pais == \"Ucrania\":\n",
        "        return {\"pais\": \"Ucrania\", \"habitantes\": 35_660_000}\n",
        "    elif pais == \"Alemania\":\n",
        "        return {\"pais\": \"Alemania\", \"habitantes\": 84_120_000}\n",
        "    else:\n",
        "        return {\"error\": \"Valor no encontrado\"}\n",
        "\n",
        "herramientas_mapeo = {\"numero_habitantes\" : numero_habitantes}\n",
        "\n",
        "# --- Generar Modelo\n",
        "credentials, project_id = google.auth.default()\n",
        "vertexai.init(project=project_id, location=\"us-central1\")\n",
        "\n",
        "context = \"\"\"\n",
        "You are an expert in geography, history and politics of Central Europe.\n",
        "You can answer general questions, but when population data is needed,\n",
        "you must call the function numero_habitantes. When asked about other countries,\n",
        "say you are not qualified to answer questions about other countries.\n",
        "\"\"\"\n",
        "model_name = \"gemini-2.5-flash-lite\"\n",
        "model = GenerativeModel(model_name, system_instruction = context)\n",
        "\n",
        "\n",
        "# --- Web UI con Streamlit\n",
        "st.title(\"Chat con Gemini\")\n",
        "prompt = st.text_input(\"Ask me about Central Europe\")\n",
        "if st.button(\"Submit\") and prompt.strip():\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(prompt)\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        with st.spinner(\"Thinking...\"):\n",
        "            try:\n",
        "    response = st.session_state.chat.send_message(prompt)\n",
        "    part = response.candidates[0].content.parts[0]\n",
        "    if part.function_call:\n",
        "        fn_name = part.function_call.name\n",
        "        fn_args = json.loads(part.function_call.arguments)\n",
        "\n",
        "        st.info(f\"üõ†Ô∏è El agente est√° usando la herramienta: `{fn_name}`\")\n",
        "        if fn_name in herramientas_mapeo:\n",
        "            fn_result = herramientas_mapeo[fn_name](**fn_args)\n",
        "\n",
        "            response = st.session_state.chat.send_message(\n",
        "                Part.from_function_call_result(\n",
        "                    name=fn_name,\n",
        "                    response=json.dumps(fn_result)\n",
        "                )\n",
        "            )\n",
        "\n",
        "  st.write(response.candidates[0].content.parts[0].text)\n",
        " except Exception as e:\n",
        "                    st.error(f\"Error en la l√≥gica del agente: {str(e)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
      "metadata": {
        "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
        "outputId": "dc484a10-4d4f-4e25-d746-5dd5712aee68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.128.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.192.117.78:8501\u001b[0m\n",
            "\u001b[0m\n",
            "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
            "  warning_logs.show_deprecation_warning()\n"
          ]
        }
      ],
      "source": [
        "!streamlit run gemini-chat.py --server.port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c3c700-6abf-41db-8ab5-1920808b48dd",
      "metadata": {
        "id": "89c3c700-6abf-41db-8ab5-1920808b48dd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "environment": {
      "kernel": "conda-base-py",
      "name": "workbench-notebooks.m137",
      "type": "gcloud",
      "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel) (Local)",
      "language": "python",
      "name": "conda-base-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}