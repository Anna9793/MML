{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c0ac1fc-d269-43c9-8030-5bc88e7d3a05",
    "outputId": "b29cdff1-a6b8-475b-dc4b-0bcc4dd5faf0"
   },
   "outputs": [],
   "source": [
    "!gcloud services enable aiplatform.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
   "metadata": {
    "id": "0f63d9a2-d27d-4d1b-ba4d-63a8e216d73e",
    "outputId": "971b551f-92dd-41f4-cf74-cd035bf39f47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                 NETWORK  DIRECTION  PRIORITY  ALLOW     DENY  DISABLED\n",
      "allow-imc-streamlit  default  INGRESS    1000      tcp:8501        False\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "gcloud compute firewall-rules create allow-imc-streamlit \\\n",
    "    --direction=INGRESS \\\n",
    "    --priority=1000 \\\n",
    "    --network=default \\\n",
    "    --action=ALLOW \\\n",
    "    --rules=tcp:8501 \\\n",
    "    --source-ranges=0.0.0.0/0 2> /dev/null\n",
    "\n",
    "gcloud compute firewall-rules list --filter name='allow-imc-streamlit' 2> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b590032e-d147-4b6b-bea9-4d6d8d64fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "countries_data = {\n",
    "    \"Poland\": {\n",
    "        \"capital\": \"Warsaw\",\n",
    "        \"population\": 38_750_000,\n",
    "        \"area_km2\": 312_696,\n",
    "        \"currency\": \"Z≈Çoty (PLN)\",\n",
    "        \"eu_member\": True,\n",
    "        \"language\": \"Polish\"\n",
    "    },\n",
    "    \"Germany\": {\n",
    "        \"capital\": \"Berlin\",\n",
    "        \"population\": 84_120_000,\n",
    "        \"area_km2\": 357_022,\n",
    "        \"currency\": \"Euro (EUR)\",\n",
    "        \"eu_member\": True,\n",
    "        \"language\": \"German\"\n",
    "    },\n",
    "    \"Ukraine\": {\n",
    "        \"capital\": \"Kyiv\",\n",
    "        \"population\": 35_660_000,\n",
    "        \"area_km2\": 603_628,\n",
    "        \"currency\": \"Hryvnia (UAH)\",\n",
    "        \"eu_member\": False,\n",
    "        \"language\": \"Ukrainian\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def country_info_anna(country: str):\n",
    "  info = countries_data.get(country)\n",
    "\n",
    "  if not info:\n",
    "    return {\"error\" : \"Country not found\",\n",
    "            \"Available countries\":list(countries_data.keys())\n",
    "    }\n",
    "\n",
    "  return {\n",
    "        \"country\": country,\n",
    "        \"data\": info\n",
    "    }\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "# --- Web UI con Streamlit\n",
    "st.title(\"Chat with Gemini\")\n",
    "if \"chat\" not in st.session_state:\n",
    "    st.session_state.chat = model.start_chat()\n",
    "prompt = st.text_input(\"Ask me about Central Europe\")\n",
    "if st.button(\"Submit\") and prompt.strip():\n",
    "    st.chat_message(\"user\").write(prompt)\n",
    "\n",
    "    try:\n",
    "        response = st.session_state.chat.send_message(prompt)\n",
    "        part = response.candidates[0].content.parts[0]\n",
    "\n",
    "        if part.function_call:\n",
    "            fn_name = part.function_call.name\n",
    "            fn_args = dict(part.function_call.args)\n",
    "\n",
    "            if fn_name in tool_mapping:\n",
    "                tool_result = tool_mapping[fn_name](**fn_args)\n",
    "\n",
    "                response = st.session_state.chat.send_message(\n",
    "                    Part.from_function_response(\n",
    "                        name=fn_name,\n",
    "                        response=tool_result,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "        st.chat_message(\"assistant\").write(response.text)\n",
    "\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error: {e}\")\n",
    "        \"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45dc014c-8d00-493c-b061-b76a0612b749",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "45dc014c-8d00-493c-b061-b76a0612b749",
    "outputId": "8aacf462-6efc-4291-d160-e3d15aab5e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting gemini-chat.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile gemini-chat.py\n",
    "import streamlit as st\n",
    "import vertexai, google.auth\n",
    "from vertexai.generative_models import (\n",
    "    GenerativeModel,\n",
    "    GenerationConfig,\n",
    "    Part,\n",
    "    Tool,\n",
    "    FunctionDeclaration\n",
    ")\n",
    "import requests\n",
    "\n",
    "def obtener_datos_pais(pais: str = \"Polonia\"):\n",
    "    if pais.lower() not in [\"polonia\", \"poland\"]:\n",
    "        return {\"error\": \"Solo hay datos disponibles para Polonia\"}\n",
    "        \n",
    "import requests\n",
    "\n",
    "COUNTRY_COD = \"POL\"\n",
    "\n",
    "urls = {\n",
    "        \"population\": f\"https://api.worldbank.org/v2/country/{COUNTRY_CODE}/indicator/SP.POP.TOTL?format=json\",\n",
    "        \"gdp\": f\"https://api.worldbank.org/v2/country/{COUNTRY_CODE}/indicator/NY.GDP.MKTP.CD?format=json\",\n",
    "    }\n",
    "\n",
    "\n",
    "# --- Diccionario para mapear el nombre de la funci√≥n con la ejecuci√≥n real\n",
    "herramientas_mapeo = {\n",
    "    \"obtener_datos_pais\": obtener_datos_pais\n",
    "}\n",
    "\n",
    "# --- Creaci√≥n de las herramientas para el Modelo (Tool)\n",
    "herramientas_agente = Tool(\n",
    "    function_declarations = [\n",
    "        FunctionDeclaration.from_func(obtener_datos_pais)\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "# --- Generar Modelo\n",
    "credentials, project_id = google.auth.default()\n",
    "vertexai.init(project=project_id, location=\"us-central1\")\n",
    "\n",
    "context = \"\"\"\n",
    "Eres un asistente experto en todo que concierne a pais centroeuropeo Polonia.\n",
    "Tu objetivo es ayudar a turistas y locales.\n",
    "Si realizan preguntas generales del pais {pais} (monumentos, fiestas, costumbres, ...), responde de forma correcta.\n",
    "Si te preguntan por datos t√©cnicos del pais {pais}, usa las herramientas disponibles. Presenta los datos de la siguiente forma:\n",
    "DATOS DE POLONIA: \n",
    "- Habitantes: {info.poblacion}\n",
    "- Superficie: {superficie_km2}\n",
    "Si preguntan sobre otro contenido no relacionado con el {pais}, responde \"No estoy programado para resolver esa pregunta\".\n",
    "\"\"\"\n",
    "model_name = \"gemini-2.5-flash-lite\"\n",
    "model = GenerativeModel(model_name, system_instruction = context)\n",
    "\n",
    "st.title(\"Chat with Gemini\")\n",
    "if \"chat\" not in st.session_state and model:\n",
    "    st.session_state.chat = model.start_chat()\n",
    "    \n",
    "if model:\n",
    "    prompt = st.text_area(\"Introduce tu prompt:\")\n",
    "    if st.button(\"Generar Respuesta\"):\n",
    "        # --- Mostrar historial previo \n",
    "        if prompt.strip():\n",
    "            with st.chat_message(\"user\"):\n",
    "                st.write(prompt)\n",
    "            # ----------------------------------\n",
    "            #  L√≥gica del Agente\n",
    "            # ----------------------------------\n",
    "            with st.chat_message(\"assistant\"):\n",
    "                with st.spinner(\"El agente est√° pensando...\"):\n",
    "                    try:\n",
    "                        # --- Env√≠o del mensaje al modelo\n",
    "                        response = st.session_state.chat.send_message(prompt)\n",
    "                        # --- Comprobaci√≥n de si el Agente necesita usar una herramienta (Function Calling)\n",
    "                        part = response.candidates[0].content.parts[0]\n",
    "                        if part.function_call:\n",
    "                            st.info(f\"üõ†Ô∏è El agente est√° usando la herramienta: `{part.function_call.name}`\") \n",
    "                            # --- Extraer nombre de la funci√≥n y argumentos\n",
    "                            fn_name = part.function_call.name\n",
    "                            fn_args = {key: val for key, val in part.function_call.args.items()}\n",
    "                            # --- Ejecutar la funci√≥n real de Python \n",
    "                            if fn_name in herramientas_mapeo:\n",
    "                                api_response = herramientas_mapeo[fn_name](**fn_args)\n",
    "                                # --- Devolver el resultado de la funci√≥n al modelo para que genere la respuesta final\n",
    "                                response = st.session_state.chat.send_message(\n",
    "                                    Part.from_function_response(\n",
    "                                        name=fn_name,\n",
    "                                        response={\n",
    "                                            \"content\": api_response,\n",
    "                                        },\n",
    "                                    )\n",
    "                                )                            \n",
    "                        # --- Mostrar la respuesta final (texto natural)\n",
    "                        st.write(response.text)\n",
    "                    except Exception as e:\n",
    "                        st.error(f\"Error en la l√≥gica del agente: {str(e)}\")\n",
    "else:\n",
    "    st.error(\"Error de inicializaci√≥n. Revisa logs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "11158fb6-6532-4dde-821c-c5c74d4b7b39",
    "outputId": "25b7cae6-a3a5-47d2-9b1d-a8bc87012d1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
      "\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://10.128.0.2:8501\u001b[0m\n",
      "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.61.30.178:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/google/api_core/_python_version_support.py:266: FutureWarning: You are using a Python version (3.10.19) which Google will stop supporting in new releases of google.api_core once it reaches its end of life (2026-10-04). Please upgrade to the latest Python version, or at least Python 3.11, to continue receiving updates for google.api_core past that date.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.10/site-packages/vertexai/generative_models/_generative_models.py:433: UserWarning: This feature is deprecated as of June 24, 2025 and will be removed on June 24, 2026. For details, see https://cloud.google.com/vertex-ai/generative-ai/docs/deprecations/genai-vertexai-sdk.\n",
      "  warning_logs.show_deprecation_warning()\n",
      "/opt/conda/lib/python3.10/site-packages/proto/marshal/rules/enums.py:37: UserWarning: Unrecognized FinishReason enum value: 15\n",
      "  warnings.warn(\n",
      "^C\n",
      "\u001b[34m  Stopping...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!streamlit run gemini-chat.py --server.port 8501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "55312120-dc69-4af4-8e37-6ddf6de4e4f1",
    "outputId": "14519cbd-08c4-4309-9d04-688ee238859c"
   },
   "outputs": [],
   "source": [
    "!pip install --quiet streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aef9e72-a6c1-4a89-adee-bf25c025e265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m137",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m137"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
